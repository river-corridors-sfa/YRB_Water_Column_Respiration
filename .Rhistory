'Column_or_Row_Name' = as.character()	,
'Unit' = as.character(),
'Definition' = as.character(),
'Data_Type' = as.character(),
'Term_Type' = as.character()
)
for (i in csv) {
data <- read_csv(i)
view(data)
skip <-
(readline(prompt = "What line has the column headers? (enter 0 if in correct place) "))
if(skip == 0){
cols <- colnames(data)
} else {
rm(data)
data <- read_csv(i, skip = as.numeric(skip), locale=locale(encoding="latin1"))
cols <- colnames(data)
}
for (j in cols) {
combine <- combine %>%
add_row(
'Column_or_Row_Name' = j	,
'Unit' = '',
'Definition' = '',
'Data_Type' = '',
'Term_Type' = 'column_header'
)
}
for (k in row_heads) {
if (k %in% data$Field_Name) {
combine <- combine %>%
add_row(
'Column_or_Row_Name' = k	,
'Unit' = '',
'Definition' = '',
'Data_Type' = '',
'Term_Type' = 'row_header'
)
} else {
}
}
rm(data)
}
flmd_dd_header <- c('File_Name',
'File_Description',
'Missing_Value_Codes',
'File_Path',
'Standard',
'Date_Start',
'Date_End',
'Column_or_Row_Name',
'Unit',
'Definition',
'Data_Type',
'Term_Type')
for (m in flmd_dd_header) {
combine <- combine %>%
add_row(
'Column_or_Row_Name' = m	,
'Unit' = '',
'Definition' = '',
'Data_Type' = '',
'Term_Type' = 'column_header'
)
}
duplicate_n <- combine %>%
group_by(Column_or_Row_Name)%>%
count() %>%
filter(n > 1)
duplicates <- paste(duplicate_n$Column_or_Row_Name, collapse = ', ')
user <-
(readline(prompt =
if (is_empty(duplicates)){
print('No duplicates. Can the duplicates be removed? (Y/N)')
} else {
paste('Column or Row name(s) ', duplicates, 'is/are duplicated. Can the duplicates be removed? (Y/N)', sep = " ")
}
))
if(user == "Y") {
dd <- combine %>%
unique()
}
populate_dd <- tibble("Column_or_Row_Name" = as.character(),
"Unit" = as.character(),
"Definition" = as.character(),
"Data_Type" = as.character(),
"Term_Type" = as.character())
for (i in 1:nrow(dd)) {
row <- dd %>%
slice(i)
column <- row %>%
select(Column_or_Row_Name)%>%
pull()
dd_database_filter <- dd_database %>%
filter(Column_or_Row_Name == column)
if(nrow(dd_database_filter) < 1){
populate_dd <- populate_dd %>%
add_row(Column_or_Row_Name = row$Column_or_Row_Name,
Unit = '',
Definition = '',
Data_Type = '',
Term_Type = row$Term_Type)
}else if(nrow(dd_database_filter) == 1) {
populate_dd <- populate_dd %>%
add_row(Column_or_Row_Name = dd_database_filter$Column_or_Row_Name,
Unit = dd_database_filter$Unit,
Definition = dd_database_filter$Definition,
Data_Type = dd_database_filter$Data_Type,
Term_Type = row$Term_Type)
} else {
view(dd_database_filter)
correct_definition <-  readline(prompt = 'Which row has the correct definition?')
dd_database_filter <- dd_database_filter %>%
slice(as.numeric(correct_definition))
populate_dd <- populate_dd %>%
add_row(Column_or_Row_Name = dd_database_filter$Column_or_Row_Name,
Unit = dd_database_filter$Unit,
Definition = dd_database_filter$Definition,
Data_Type = dd_database_filter$Data_Type,
Term_Type = row$Term_Type)
}
}
write_csv(populate_dd, dd_outdir)
files <- list.files(dp_dir, full.names = T, recursive = T)
combine2 <- tibble(
'File_Name' = as.character()	,
'File_Description' = as.character(),
'Standard' = as.character(),
'Date_Start' = as.character(),
"Date_End" = as.character(),
'Missing_Value_Codes' = as.character(),
'File_Path' = as.character()
)
for (file in files){
short_name <- str_remove(file, dp_dir)
file_name <- path_file(short_name)
path <- path_dir(short_name)
combine2 <- combine2 %>%
add_row( 'File_Name' = file_name	,
'File_Description' = '',
"Standard" = '',
'Date_Start' = '',
"Date_End" = '',
'Missing_Value_Codes' = '',
'File_Path' = path)
}
flmd_path <- str_remove(flmd_outdir, flmd_outfile)
flmd <- combine2 %>%
# filter(!str_detect(File_Name, pattern))%>%
# add_row(temp) %>%
add_row('File_Name' = flmd_outfile	,
'File_Description' = '',
"Standard" = '',
'Date_Start' = '',
"Date_End" = '',
'Missing_Value_Codes' = '',
'File_Path' = flmd_path,
.before = 1)
populate_flmd <- tibble("File_Name" = as.character(),
"File_Description" = as.character(),
"Standard" = as.character(),
"Date_Start" = as.character(),
"Date_End" = as.character(),
"Missing_Value_Codes" = as.character(),
"File_Path" = as.character())
for (j in 1:nrow(flmd)) {
flmd_row <- flmd %>%
slice(j)
flmd_column <- flmd_row %>%
select(File_Name)%>%
pull()
flmd_database_filter <- flmd_database %>%
filter(File_Name == flmd_column)
if(nrow(flmd_database_filter) < 1){
populate_flmd <- populate_flmd %>%
add_row("File_Name" = flmd_row$File_Name,
"File_Description" = '',
"Standard" = '',
"Date_Start" = '',
"Date_End" = '',
"Missing_Value_Codes" = '',
"File_Path" = flmd_row$File_Path)
}else if(nrow(flmd_database_filter) == 1) {
populate_flmd <- populate_flmd %>%
add_row("File_Name" = flmd_row$File_Name,
"File_Description" = flmd_database_filter$File_Description,
"Standard" = flmd_database_filter$Standard,
"Date_Start" = '',
"Date_End" = '',
"Missing_Value_Codes" = flmd_database_filter$Missing_Value_Codes,
"File_Path" = flmd_row$File_Path)
} else {
view(flmd_database_filter)
correct_definition <-  readline(prompt = 'Which row has the correct definition?')
flmd_database_filter <- flmd_database_filter %>%
slice(as.numeric(correct_definition))
populate_flmd <- populate_flmd %>%
add_row("File_Name" = flmd_row$File_Name,
"File_Description" = flmd_database_filter$File_Description,
"Standard" = flmd_database_filter$Standard,
"Date_Start" = '',
"Date_End" = '',
"Missing_Value_Codes" = flmd_database_filter$Missing_Value_Codes,
"File_Path" = flmd_row$File_Path)
}
}
write_csv(populate_flmd, flmd_outdir)
library(tidyverse)
library(tools)
# ================================= User inputs ================================
photo_dir <- 'C:/Brieanne/SSF_Underwater_Sensor_Photos-and-Videos'
out_dir <- 'C:/Brieanne/SSF_Underwater_Sensor_Photos-and-Videos/Formatted'
study_code <- 'SSF'
# ============================== rename the images =============================
file_list <-  list.files(photo_dir, recursive = T, full.names = T)
i <- file_list[1]
date <- unlist(str_split(i, '/')) [4] %>%
str_remove_all("-")
site <- unlist(str_split(i, '/')) [5]
extension <- file_ext(i)
subfolder_files <- list.files(dirname(i), full.names = T)
subfolder_count <- tibble(
file = subfolder_files)
subfolder_count <- subfolder_count %>%
add_column(number = 1:nrow(subfolder_count))
subfolder <- dirname(i)
number <- subfolder_count %>%
filter(file %in% i) %>%
select(number) %>%
pull() %>%
as.numeric()
str_detect(i, 'Underwater')
if (str_detect(i, 'Grain_Size_Grid_Photos') == TRUE) {
out_file <- paste(out_dir, '/', study_code, '_', site,'_', date,'_GrainSize_', number,'.', extension, sep = '')
} else if (str_detect(i, 'Environmental_Context_Photos') == TRUE) {
out_file <- paste(out_dir,'/', study_code, '_', site,'_', date,'_EnvContext_', number,'.', extension , sep = '')
} else if (str_detect(i, 'Underwater') == TRUE) {
out_file <- paste(out_dir,'/', study_code, '_', site,'_', date,'_EnvContext_', number,'.', extension , sep = '')
} else if (str_detect(i, 'Metadata_Sheet_Photos') == TRUE) {
out_file <- paste(out_dir,'/', study_code, '_', site,'_', date,'_MetadataSheet_', number,'.', extension , sep = '')
} else if (str_detect(i, 'People_Working_Photos') == TRUE) {
out_file <- paste(out_dir,'/', study_code, '_', site,'_', date,'_PeopleWorking_', number,'.', extension , sep = '')
}
out_file
for (i in file_list){
date <- unlist(str_split(i, '/')) [4] %>%
str_remove_all("-")
site <- unlist(str_split(i, '/')) [5]
extension <- file_ext(i)
subfolder_files <- list.files(dirname(i), full.names = T)
subfolder_count <- tibble(
file = subfolder_files)
subfolder_count <- subfolder_count %>%
add_column(number = 1:nrow(subfolder_count))
subfolder <- dirname(i)
number <- subfolder_count %>%
filter(file %in% i) %>%
select(number) %>%
pull() %>%
as.numeric()
if (str_detect(i, 'Grain_Size_Grid_Photos') == TRUE) {
out_file <- paste(out_dir, '/', study_code, '_', site,'_', date,'_GrainSize_', number,'.', extension, sep = '')
} else if (str_detect(i, 'Environmental_Context_Photos') == TRUE) {
out_file <- paste(out_dir,'/', study_code, '_', site,'_', date,'_EnvContext_', number,'.', extension , sep = '')
} else if (str_detect(i, 'Underwater') == TRUE) {
out_file <- paste(out_dir,'/', study_code, '_', site,'_', date,'_EnvContext_', number,'.', extension , sep = '')
} else if (str_detect(i, 'Metadata_Sheet_Photos') == TRUE) {
out_file <- paste(out_dir,'/', study_code, '_', site,'_', date,'_MetadataSheet_', number,'.', extension , sep = '')
} else if (str_detect(i, 'People_Working_Photos') == TRUE) {
out_file <- paste(out_dir,'/', study_code, '_', site,'_', date,'_PeopleWorking_', number,'.', extension , sep = '')
}
file.copy(i, out_file)
}
library(tidyverse)
library(magick)
library(rsvg)
library(fs)
# ================================= User inputs ================================
photo_dir <- 'Z:/RC3/00_Schneider_Springs_Fire_2023/01_FieldPhotos/01_RawData/Metadata_Sheet_Photos'
out_dir <- 'Z:/RC3/00_Schneider_Springs_Fire_2023/01_FieldPhotos/01_RawData/Metadata_Sheet_Photo/'
# ================================= convert photo ==============================
photos <- list.files(photo_dir, '.HEIC|.heic', full.names = T, recursive = T)
photo_dir <- 'C:/Brieanne/SSF_Environmental_Context_Photos/Formatted/'
out_dir <- 'C:/Brieanne/SSF_Environmental_Context_Photos/Formatted/'
photos <- list.files(photo_dir, '.HEIC|.heic', full.names = T, recursive = T)
photo <- photos[1]
photo_read <- magick::image_read(photo)
file_name <- path_file(photo) %>%
str_replace(., '.heic', '.jpeg')%>%
str_replace(., '.HEIC', '.jpeg')
new_name <- paste0(out_dir, file_name)
new_name
photo
image_write(photo_read, new_name, format = 'jpeg')
file_delete(photo)
rm(photo_read)
file_delete(photo)
photos <- list.files(photo_dir, '.HEIC|.heic', full.names = T, recursive = T)
for (photo in photos) {
photo_read <- magick::image_read(photo)
file_name <- path_file(photo) %>%
str_replace(., '.heic', '.jpeg')%>%
str_replace(., '.HEIC', '.jpeg')
new_name <- paste0(out_dir, file_name)
# new_name <- photo %>%
#   str_replace(., '.heic', '.jpeg')%>%
#   str_replace(., '.HEIC', '.jpeg')
#
image_write(photo_read, new_name, format = 'jpeg')
}
library(tidyverse)
library(magick)
library(rsvg)
library(fs)
# ================================= User inputs ================================
photo_dir <- 'C:/Brieanne/SSF_Environmental_Context_Photos/Formatted/'
out_dir <- 'C:/Brieanne/SSF_Environmental_Context_Photos/Formatted/'
# ================================= convert photo ==============================
photos <- list.files(photo_dir, '.HEIC|.heic', full.names = T, recursive = T)
for (photo in photos) {
photo_read <- magick::image_read(photo)
file_name <- path_file(photo) %>%
str_replace(., '.heic', '.jpeg')%>%
str_replace(., '.HEIC', '.jpeg')
new_name <- paste0(out_dir, file_name)
# new_name <- photo %>%
#   str_replace(., '.heic', '.jpeg')%>%
#   str_replace(., '.HEIC', '.jpeg')
#
image_write(photo_read, new_name, format = 'jpeg')
}
library(tidyverse)
library(tools)
# ================================= User inputs ================================
photo_dir <- 'C:/Brieanne/SSF_Environmental_Context_Photos/2023-07-27/S02/'
out_dir <- 'C:/Brieanne/SSF_Underwater_Sensor_Photos-and-Videos/Formatted'
study_code <- 'SSF'
# ============================== rename the images =============================
file_list <-  list.files(photo_dir, recursive = T, full.names = T)
for (i in file_list){
date <- unlist(str_split(i, '/')) [4] %>%
str_remove_all("-")
site <- unlist(str_split(i, '/')) [5]
extension <- file_ext(i)
subfolder_files <- list.files(dirname(i), full.names = T)
subfolder_count <- tibble(
file = subfolder_files)
subfolder_count <- subfolder_count %>%
add_column(number = 1:nrow(subfolder_count))
subfolder <- dirname(i)
number <- subfolder_count %>%
filter(file %in% i) %>%
select(number) %>%
pull() %>%
as.numeric()
if (str_detect(i, 'Grain_Size_Grid_Photos') == TRUE) {
out_file <- paste(out_dir, '/', study_code, '_', site,'_', date,'_GrainSize_', number,'.', extension, sep = '')
} else if (str_detect(i, 'Environmental_Context_Photos') == TRUE) {
out_file <- paste(out_dir,'/', study_code, '_', site,'_', date,'_EnvContext_', number,'.', extension , sep = '')
} else if (str_detect(i, 'Underwater') == TRUE) {
out_file <- paste(out_dir,'/', study_code, '_', site,'_', date,'_EnvContext_', number,'.', extension , sep = '')
} else if (str_detect(i, 'Metadata_Sheet_Photos') == TRUE) {
out_file <- paste(out_dir,'/', study_code, '_', site,'_', date,'_MetadataSheet_', number,'.', extension , sep = '')
} else if (str_detect(i, 'People_Working_Photos') == TRUE) {
out_file <- paste(out_dir,'/', study_code, '_', site,'_', date,'_PeopleWorking_', number,'.', extension , sep = '')
}
file.copy(i, out_file)
}
out_dir <- 'C:/Brieanne/SSF_Environmental_Context_Photos/Formatted/'
study_code <- 'SSF'
file_list <-  list.files(photo_dir, recursive = T, full.names = T)
for (i in file_list){
date <- unlist(str_split(i, '/')) [4] %>%
str_remove_all("-")
site <- unlist(str_split(i, '/')) [5]
extension <- file_ext(i)
subfolder_files <- list.files(dirname(i), full.names = T)
subfolder_count <- tibble(
file = subfolder_files)
subfolder_count <- subfolder_count %>%
add_column(number = 1:nrow(subfolder_count))
subfolder <- dirname(i)
number <- subfolder_count %>%
filter(file %in% i) %>%
select(number) %>%
pull() %>%
as.numeric()
if (str_detect(i, 'Grain_Size_Grid_Photos') == TRUE) {
out_file <- paste(out_dir, '/', study_code, '_', site,'_', date,'_GrainSize_', number,'.', extension, sep = '')
} else if (str_detect(i, 'Environmental_Context_Photos') == TRUE) {
out_file <- paste(out_dir,'/', study_code, '_', site,'_', date,'_EnvContext_', number,'.', extension , sep = '')
} else if (str_detect(i, 'Underwater') == TRUE) {
out_file <- paste(out_dir,'/', study_code, '_', site,'_', date,'_EnvContext_', number,'.', extension , sep = '')
} else if (str_detect(i, 'Metadata_Sheet_Photos') == TRUE) {
out_file <- paste(out_dir,'/', study_code, '_', site,'_', date,'_MetadataSheet_', number,'.', extension , sep = '')
} else if (str_detect(i, 'People_Working_Photos') == TRUE) {
out_file <- paste(out_dir,'/', study_code, '_', site,'_', date,'_PeopleWorking_', number,'.', extension , sep = '')
}
file.copy(i, out_file)
}
i <- file_list[1]
date <- unlist(str_split(i, '/')) [4] %>%
str_remove_all("-")
site <- unlist(str_split(i, '/')) [5]
library(tidyverse)
library(tools)
# ================================= User inputs ================================
photo_dir <- 'C:/Brieanne/SSF_Environmental_Context_Photos/2023-09-25/S23/'
out_dir <- 'C:/Brieanne/SSF_Environmental_Context_Photos/Formatted/'
study_code <- 'SSF'
# ============================== rename the images =============================
file_list <-  list.files(photo_dir, recursive = T, full.names = T)
file_list
i <- file_list[1]
date <- unlist(str_split(i, '/')) [4] %>%
str_remove_all("-")
site <- unlist(str_split(i, '/')) [5]
extension <- file_ext(i)
subfolder_files <- list.files(dirname(i), full.names = T)
subfolder_count <- tibble(
file = subfolder_files)
subfolder_count <- subfolder_count %>%
add_column(number = 1:nrow(subfolder_count))
subfolder <- dirname(i)
number <- subfolder_count %>%
filter(file %in% i) %>%
select(number) %>%
pull() %>%
as.numeric()
if (str_detect(i, 'Grain_Size_Grid_Photos') == TRUE) {
out_file <- paste(out_dir, '/', study_code, '_', site,'_', date,'_GrainSize_', number,'.', extension, sep = '')
} else if (str_detect(i, 'Environmental_Context_Photos') == TRUE) {
out_file <- paste(out_dir,'/', study_code, '_', site,'_', date,'_EnvContext_', number,'.', extension , sep = '')
} else if (str_detect(i, 'Underwater') == TRUE) {
out_file <- paste(out_dir,'/', study_code, '_', site,'_', date,'_EnvContext_', number,'.', extension , sep = '')
} else if (str_detect(i, 'Metadata_Sheet_Photos') == TRUE) {
out_file <- paste(out_dir,'/', study_code, '_', site,'_', date,'_MetadataSheet_', number,'.', extension , sep = '')
} else if (str_detect(i, 'People_Working_Photos') == TRUE) {
out_file <- paste(out_dir,'/', study_code, '_', site,'_', date,'_PeopleWorking_', number,'.', extension , sep = '')
}
out_file
for (i in file_list){
date <- unlist(str_split(i, '/')) [4] %>%
str_remove_all("-")
site <- unlist(str_split(i, '/')) [5]
extension <- file_ext(i)
subfolder_files <- list.files(dirname(i), full.names = T)
subfolder_count <- tibble(
file = subfolder_files)
subfolder_count <- subfolder_count %>%
add_column(number = 1:nrow(subfolder_count))
subfolder <- dirname(i)
number <- subfolder_count %>%
filter(file %in% i) %>%
select(number) %>%
pull() %>%
as.numeric()
if (str_detect(i, 'Grain_Size_Grid_Photos') == TRUE) {
out_file <- paste(out_dir, '/', study_code, '_', site,'_', date,'_GrainSize_', number,'.', extension, sep = '')
} else if (str_detect(i, 'Environmental_Context_Photos') == TRUE) {
out_file <- paste(out_dir,'/', study_code, '_', site,'_', date,'_EnvContext_', number,'.', extension , sep = '')
} else if (str_detect(i, 'Underwater') == TRUE) {
out_file <- paste(out_dir,'/', study_code, '_', site,'_', date,'_EnvContext_', number,'.', extension , sep = '')
} else if (str_detect(i, 'Metadata_Sheet_Photos') == TRUE) {
out_file <- paste(out_dir,'/', study_code, '_', site,'_', date,'_MetadataSheet_', number,'.', extension , sep = '')
} else if (str_detect(i, 'People_Working_Photos') == TRUE) {
out_file <- paste(out_dir,'/', study_code, '_', site,'_', date,'_PeopleWorking_', number,'.', extension , sep = '')
}
file.copy(i, out_file)
}
source("C:/Users/forb086/OneDrive - PNNL/Data Generation and Files/R code/Data_Package_Code/convert_images.R", echo=TRUE)
photos
source("C:/Users/forb086/OneDrive - PNNL/Data Generation and Files/R code/Data_Package_Code/rename_field_photos.R", echo=TRUE)
source("C:/Users/forb086/OneDrive - PNNL/Data Generation and Files/R code/Data_Package_Code/convert_images.R", echo=TRUE)
library(tidyverse) #keep it tidy
library(raster) # work with rasters, NOTE: masks dplyr::select
library(janitor) # clean_names()
library(ggthemes) # theme_map()
library(ggsflabel) # add labels to sf objects
library(ggnewscale) # set multiple color scales
library(ggspatial) # add north arrow and scale bar
library(nhdplusTools) # get watershed boundary/flowlines
library(elevatr) # pull elevation maps
library(sf) # tidy spatial
library(spData)
library(cowplot)
library(rstudioapi)
library(viridis)
rm(list=ls(all=T))
# Setting wd to parent folder
current_path <- rstudioapi::getActiveDocumentContext()$path
setwd(dirname(current_path))
setwd("./..")
# ================================= User inputs ================================
metadata_file <- 'C:/Users/forb086/Downloads/v2_SFA_SpatialStudy_2021_SampleData/SPS_Sample_Field_Metadata.csv'
data_file <- './Data/Multiple_linear_regression/spatial_data.csv'
yrb_shp_dir <- './Data/Maps/YakimaRiverBasin_Boundary'
cluster_shp_dir <- './Data/Maps/YRB_Cluster'
common_crs = 4326
# ============================== read in and merge =============================
metadata <- read_csv(metadata_file) %>%
dplyr::select(Site_ID, Latitude, Longitude)
data <- read_csv(data_file) %>%
dplyr::select(IDmapping.Site_ID, DO.slope.mgday)
merge <- data %>%
left_join(metadata, by = c('IDmapping.Site_ID' = 'Site_ID')) %>%
rename(Site_ID = IDmapping.Site_ID,
ER_wc = DO.slope.mgday) %>%
arrange(ER_wc)
View(merge)
write_csv(merge, './Data/Maps/SPS_ER_WC_Coords.csv')
View(merge)
